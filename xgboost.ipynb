{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already satisfied: numpy in c:\\users\\owen\\documents\\vscode\\xgboost-py\\.conda\\lib\\site-packages (2.1.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\owen\\documents\\vscode\\xgboost-py\\.conda\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\owen\\documents\\vscode\\xgboost-py\\.conda\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: xgboost in c:\\users\\owen\\documents\\vscode\\xgboost-py\\.conda\\lib\\site-packages (2.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\owen\\documents\\vscode\\xgboost-py\\.conda\\lib\\site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\owen\\documents\\vscode\\xgboost-py\\.conda\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\owen\\documents\\vscode\\xgboost-py\\.conda\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\owen\\documents\\vscode\\xgboost-py\\.conda\\lib\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\owen\\documents\\vscode\\xgboost-py\\.conda\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\owen\\documents\\vscode\\xgboost-py\\.conda\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\owen\\documents\\vscode\\xgboost-py\\.conda\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy pandas scikit-learn xgboost  -i https://mirrors.aliyun.com/pypi/simple/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考资料：\n",
    "\n",
    "* 文字：https://www.zhihu.com/question/58883125/answer/2551395292\n",
    "* 视频：https://www.bilibili.com/video/BV1Zk4y1F7JE/\n",
    "* 代码：https://randomrealizations.com/posts/xgboost-from-scratch/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 代表一颗树中的某个node\n",
    "class TreeBooster():\n",
    "    def __init__(self, X, g, h, params, max_depth, idxs=None):\n",
    "        # 各种超参数\n",
    "        self.params = params\n",
    "        self.max_depth = max_depth\n",
    "        assert self.max_depth >= 0, 'max_depth must be nonnegative'\n",
    "        self.min_child_weight = params['min_child_weight'] if params['min_child_weight'] else 1.0  \n",
    "        self.colsample_bynode = params['colsample_bynode'] if params['colsample_bynode'] else 1.0\n",
    "        \n",
    "        self.reg_lambda = params['reg_lambda'] if params['reg_lambda'] else 1.0 # λ超参，公式的重要部分\n",
    "        self.gamma = params['gamma'] if params['gamma'] else 0.0 # γ超参，公式的重要部分\n",
    "        \n",
    "        # 每个样本的Loss一阶导数，常数\n",
    "        if isinstance(g, pd.Series):\n",
    "            g = g.values\n",
    "        # 每个样本的Loss二阶导数，常数\n",
    "        if isinstance(h, pd.Series): \n",
    "            h = h.values\n",
    "            \n",
    "        # 参与训练的样本index，默认所有\n",
    "        if idxs is None: \n",
    "            idxs = np.arange(len(g))\n",
    "            \n",
    "        # X：特征   g：Loss一阶导数   h：Loss二阶导数，idxs：参与训练的样本index\n",
    "        self.X, self.g, self.h, self.idxs = X, g, h, idxs\n",
    "        \n",
    "        # n：样本数, c：特征数\n",
    "        self.n, self.c = len(idxs), X.shape[1] \n",
    "        \n",
    "        # Tree目标最小化的时候，Wj的取值计算.\n",
    "        # 如果当前Node就是叶子，那么其Wj就是所有传入的样本计算而成的\n",
    "        self.value = -g[idxs].sum() / (h[idxs].sum() + self.reg_lambda) # Eq (5)\n",
    "        self.best_score_so_far = 0.\n",
    "        self.is_leaf=True\n",
    "        \n",
    "        # 如果允许分裂节点，那么就继续递归\n",
    "        if self.max_depth > 0:\n",
    "            self._maybe_insert_child_nodes() # 为当前节点找到一个分裂条件，产生左右两颗子树，让样本落入两颗子树，每颗子树又可以继续更新自己的Wj或者继续递归分裂\n",
    "\n",
    "    def _maybe_insert_child_nodes(self):\n",
    "        # 遍历每一个特征，判断是否适合作为分裂条件\n",
    "        for i in range(self.c):\n",
    "            self._find_better_split(i)\n",
    "        \n",
    "        # 没找到合适的分裂点，那么就不分裂了，自己就是叶子，直接用value作为W值\n",
    "        if self.is_leaf: \n",
    "            return\n",
    "\n",
    "        # 作为分裂条件的特征\n",
    "        x = self.X.values[self.idxs,self.split_feature_idx]\n",
    "        \n",
    "        # <=分裂点的落入左子树\n",
    "        left_idx = np.nonzero(x <= self.threshold)[0]\n",
    "        # 其他落入右子树\n",
    "        right_idx = np.nonzero(x > self.threshold)[0]\n",
    "        # 递归构建左右子树\n",
    "        self.left = TreeBooster(self.X, self.g, self.h, self.params, self.max_depth - 1, self.idxs[left_idx])\n",
    "        self.right = TreeBooster(self.X, self.g, self.h, self.params, self.max_depth - 1, self.idxs[right_idx])\n",
    "    \n",
    "    def _find_better_split(self, feature_idx):\n",
    "        # 取出这一列特征\n",
    "        x = self.X.values[self.idxs, feature_idx]\n",
    "        # 取出所有样本的g和h导数\n",
    "        g, h = self.g[self.idxs], self.h[self.idxs]\n",
    "        \n",
    "        # 这一列特征值从小到大，对样本进行排序\n",
    "        sort_idx = np.argsort(x)\n",
    "        sort_g, sort_h, sort_x = g[sort_idx], h[sort_idx], x[sort_idx]  # g和h也跟随排序\n",
    "        \n",
    "        sum_g, sum_h = g.sum(), h.sum()\n",
    "        sum_g_right, sum_h_right = sum_g, sum_h\n",
    "        sum_g_left, sum_h_left = 0., 0.\n",
    "\n",
    "        # 遍历每一个样本\n",
    "        for i in range(0, self.n - 1):\n",
    "            g_i, h_i, x_i = sort_g[i], sort_h[i], sort_x[i]\n",
    "            \n",
    "            # 以样本i的特征值作为分割点，计算H_left,G_left,H_right,G_right\n",
    "            sum_g_left += g_i; sum_g_right -= g_i\n",
    "            sum_h_left += h_i; sum_h_right -= h_i\n",
    "            \n",
    "            # 子树不能太小\n",
    "            if sum_h_left < self.min_child_weight or sum_h_right < self.min_child_weight:\n",
    "                continue\n",
    "            \n",
    "            # 求分裂和不分裂的目标值之差，寻找差距最大的，也就是分裂后目标值变的更小的\n",
    "            gain = 0.5 * ((sum_g_left**2 / (sum_h_left + self.reg_lambda)) + (sum_g_right**2 / (sum_h_right + self.reg_lambda)) - (sum_g**2 / (sum_h + self.reg_lambda))) - self.gamma/2 # Eq(7) in the xgboost paper\n",
    "            if gain > self.best_score_so_far: \n",
    "                self.split_feature_idx = feature_idx # 用哪个特征作为条件\n",
    "                self.best_score_so_far = gain\n",
    "                self.threshold = x_i # 用哪个值作为分割点\n",
    "                self.is_leaf=False\n",
    "                \n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict_row(row) for i, row in X.iterrows()])\n",
    "\n",
    "    # 预测就是根据树的结构，将样本落入到某个叶子节点，得到该叶子节点的Wj\n",
    "    def _predict_row(self, row):\n",
    "        if self.is_leaf: \n",
    "            return self.value\n",
    "        child = self.left if row.iloc[self.split_feature_idx] <= self.threshold else self.right\n",
    "        return child._predict_row(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGBoostModel():\n",
    "    '''XGBoost from Scratch\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, params, random_seed=None):\n",
    "        self.params = defaultdict(lambda: None, params)\n",
    "        self.subsample = self.params['subsample'] if self.params['subsample'] else 1.0\n",
    "        self.learning_rate = self.params['learning_rate'] if self.params['learning_rate'] else 0.3\n",
    "        self.base_prediction = self.params['base_score'] if self.params['base_score'] else 0.5\n",
    "        self.max_depth = self.params['max_depth'] if self.params['max_depth'] else 5\n",
    "        self.rng = np.random.default_rng(seed=random_seed)\n",
    "                \n",
    "    def fit(self, X, y, objective, num_boost_round, verbose=False):\n",
    "        current_predictions = self.base_prediction * np.ones(shape=y.shape)\n",
    "        self.boosters = []\n",
    "        for i in range(num_boost_round):\n",
    "            gradients = objective.gradient(y, current_predictions) # 每个样本的Loss一阶导数，输入是目标值和累计预测值\n",
    "            hessians = objective.hessian(y, current_predictions)   # 每个样本的Loss二阶导数，输入是目标值和累计预测值\n",
    "            sample_idxs = None if self.subsample == 1.0 else self.rng.choice(len(y), size=math.floor(self.subsample*len(y)), replace=False) # 样本采样，这里先当全部样本都进入当前Tree的训练\n",
    "            booster = TreeBooster(X, gradients, hessians, self.params, self.max_depth, sample_idxs) # 根据导数和样本，以目标函数最优为目标，就能生成一棵树，然后以目标函数最优直接可以算出各叶子节点的W值\n",
    "            current_predictions += self.learning_rate * booster.predict(X)  # 更新预测值（不断boost提升而来）\n",
    "            self.boosters.append(booster)\n",
    "            if verbose: \n",
    "                print(f'[{i}] train loss = {objective.loss(y, current_predictions)}')\n",
    "            \n",
    "    def predict(self, X):\n",
    "        # 逐步提升预测值\n",
    "        return (self.base_prediction + self.learning_rate * np.sum([booster.predict(X) for booster in self.boosters], axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train&Fit Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing,load_diabetes\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "    \n",
    "X, y = load_diabetes(as_frame=True, return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SquaredErrorObjective():\n",
    "    # Loss\n",
    "    # (y_i-pred_i_minus_1)^2 / 2\n",
    "    def loss(self, y, pred):\n",
    "        return np.mean(((y - pred)**2)*0.5)\n",
    "    \n",
    "    # Loss关于Pred的一阶导数\n",
    "    def gradient(self, y, pred):\n",
    "        return pred - y\n",
    "    \n",
    "    # Loss关于Pred的二阶导数\n",
    "    def hessian(self, y, pred):\n",
    "        return np.ones(len(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 5,\n",
    "    'subsample': 0.8,\n",
    "    'reg_lambda': 1.5,\n",
    "    'gamma': 0.0,\n",
    "    'min_child_weight': 25,\n",
    "    'base_score': 0.0,\n",
    "    'tree_method': 'exact',\n",
    "    'objective': 'reg:squarederror'\n",
    "}\n",
    "num_boost_round = 50\n",
    "\n",
    "# train the from-scratch XGBoost model\n",
    "model_scratch = XGBoostModel(params)\n",
    "model_scratch.fit(X_train, y_train, SquaredErrorObjective(), num_boost_round, verbose=False)\n",
    "\n",
    "# train the library XGBoost model\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "model_xgb = xgb.train(params, dtrain, num_boost_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scratch loss: 1623.7531978943243\n",
      "xgboost loss: 1679.5604874796754\n"
     ]
    }
   ],
   "source": [
    "pred_scratch = model_scratch.predict(X_test)\n",
    "pred_xgb = model_xgb.predict(dtest)\n",
    "print(f'scratch loss: {SquaredErrorObjective().loss(y_test, pred_scratch)}')\n",
    "print(f'xgboost loss: {SquaredErrorObjective().loss(y_test, pred_xgb)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train&Fit Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "    \n",
    "X, y = load_breast_cancer(as_frame=True, return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 补充实现BCE二值交叉熵损失【二分类问题】\n",
    "class BinaryCrossEntropybjective():\n",
    "    # BCE损失函数与导数：https://blog.csdn.net/zzl12880/article/details/128403845\n",
    "    def loss(self, y, pred):\n",
    "        return np.mean(-(y * np.log(1/(1+np.exp(-pred))) + (1 - y) * np.log(1 - np.exp(-pred))))\n",
    "    \n",
    "    # Loss关于Pred的一阶导数\n",
    "    def gradient(self, y, pred):\n",
    "        return 1/(1+np.exp(-pred)) - y\n",
    "    \n",
    "    # Loss关于Pred的二阶导数\n",
    "    def hessian(self, y, pred):\n",
    "        sigmoid_value= 1/(1+np.exp(-pred))\n",
    "        return sigmoid_value * (1 - sigmoid_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 5,\n",
    "    'subsample': 0.8,\n",
    "    'reg_lambda': 1.5,\n",
    "    'gamma': 0.0,\n",
    "    'min_child_weight': 25,\n",
    "    'base_score': 0.5,\n",
    "    'tree_method': 'exact',\n",
    "    'objective': 'binary:logitraw'\n",
    "}\n",
    "num_boost_round = 50\n",
    "\n",
    "# train the from-scratch XGBoost model\n",
    "model_scratch = XGBoostModel(params, random_seed=42)\n",
    "model_scratch.fit(X_train, y_train, SquaredErrorObjective(), num_boost_round, verbose=False)\n",
    "\n",
    "def logregobj(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    preds = 1.0 / (1.0 + np.exp(-preds))\n",
    "    grad = preds - labels\n",
    "    hess = preds * (1.0 - preds)\n",
    "    return grad, hess\n",
    "\n",
    "# train the library XGBoost model\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "model_xgb = xgb.train(params, dtrain, num_boost_round,obj=logregobj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_scratch=model_scratch.predict(X_test)\n",
    "pred_xgb=model_xgb.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scratch acc:85.38011695906432\n",
      "xgboost acc:94.73684210526315\n"
     ]
    }
   ],
   "source": [
    "def accuracy(y_test,pred):\n",
    "    probs=1/(1+np.exp(-pred))\n",
    "    classes=np.zeros_like(probs)\n",
    "    classes[probs>0.5]=1\n",
    "\n",
    "    # 计算准确率\n",
    "    acc=(classes==y_test).sum()/len(classes)*100\n",
    "    # numpy转float \n",
    "    return acc.item()\n",
    "\n",
    "# 结果不如官方，原因未知\n",
    "print(f'scratch acc:{accuracy(y_test,pred_scratch)}')\n",
    "print(f'xgboost acc:{accuracy(y_test,pred_xgb)}') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
